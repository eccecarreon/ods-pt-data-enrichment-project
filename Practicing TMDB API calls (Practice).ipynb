{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99e6870-4631-423e-bed1-48b9dc111716",
   "metadata": {},
   "source": [
    "**TMDB API (Practice)** \n",
    "\n",
    "This practice assignment will reinforce important learning objectives from the previous lesson(s), and allow you to take on more challenging core assignments, preparing you for graduation.\n",
    "\n",
    "Practice and tinker with this assignment until you're comfortable performing each of the tasks. Then, be sure to submit your output as described in the steps below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1946c210-e115-4111-b385-b920bc487b99",
   "metadata": {},
   "source": [
    "**TMDB API (Practice):**\n",
    "\n",
    "**Project Planning**\n",
    "\n",
    "As discussed in the previous lesson, for the next part of your project, you will extract financial and certification data from TMDB's API for your IMDB data set. You will use an OUTER and INNER loop: a loop within a loop!\n",
    "\n",
    "The OUTER loop will loop through the start years included in the IMDB data, filter the title basics data for the selected year, and save the list of movie ids from that year to retrieve in the inner loop.\n",
    "\n",
    "The INNER loop loops through every movie id from the selected year, extracts its results from the TMDB API, and appends them to a JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9863fcca-8ebe-483f-9fac-b8d75fd57aa4",
   "metadata": {},
   "source": [
    "# **For this practice assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d1aa84-886d-45f6-9c7a-a5336d109fc1",
   "metadata": {},
   "source": [
    "You will be practicing the inner loop of API calls for a single year's list of movies from your IMDB title basics data. Specifically, you will extract the API results for every movie with a startYear of 2000.\n",
    "\n",
    "* **Read the instructions below, including the examples in the \"Getting Started\" section, before starting your work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8085eb7c-ba65-4018-861e-3a9b682518f2",
   "metadata": {},
   "source": [
    "* **Create a new notebook in your project repository called \"Practicing TMDB API calls.**\n",
    "\n",
    "**Preparation BEFORE the loop**\n",
    "* Designate a folder to save your information.\n",
    "* Define custom functions you will use for your API calls\n",
    "* Load your cleaned title basics data from Part 1 of Project 2 (or query your title_basics table in your MySQL database).\n",
    "* Define the year you wish to retrieve (2010) and create an empty list for appending error messages.\n",
    "\n",
    "**Prepare the DataFrame and JSON File**\n",
    "* **Use the selected year to define filenames and filter the data**\n",
    "    1. Define a JSON_FILE filename to save the results in progress.\n",
    "    2. Check if the file exists.\n",
    "        * if it does not exist, create the empty JSON file with with open that just contains the key \"imdb_id\"\n",
    "        * if it exists, print a message saying that it already exists.\n",
    "\n",
    "***Now that the JSON file for the results in progress exists:***\n",
    "* Filter the IMDB title basics data for the selected year and save the movie IDs from that year as \"movies_ids\".\n",
    "* Check the JSON file for previously downloaded movie IDs and filter out the movie ids that already exists in the JSON file ( to prevent duplicate API calls) by:\n",
    "    * Loading in the contents of the JSON file pd.read_json.\n",
    "        * Compare the movie_ids that were in the JSON file to your saved movie_ids_to_get.\n",
    "    * Save the final list of \"movie_ids_to_get\" by filtering out movies that already exists in the JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e332b69c-df04-4a37-8dbf-1d3ddc4e0329",
   "metadata": {},
   "source": [
    "**Perform the Loop of API Calls**\n",
    "\n",
    "Note: you have already written a function to combine the certification with the rest of the .info() from the TMDB API results in the Intro to TMDB API lesson.\n",
    "\n",
    "**Create a loop to make API calls for each id** in the YEAR specified. Include a progress bar using tqdm_notebook.\n",
    "\n",
    "***For each movie id:***\n",
    "* Extract the current ID from the API and retrieve the dictionary of results\n",
    "* Append the new results to the list from the JSON file\n",
    "* Save the updated JSON file back to the disk\n",
    "\n",
    "**Save the Results to Compressed .csv**\n",
    "* **After the loop**, save the final results for the year as a csv.gz file with the year in the filename.\n",
    "\n",
    "Note: at this point, you'll have completed the inner loop that you will need for the next part of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fd16ee-4e36-4960-b5a0-fe6fd22323fe",
   "metadata": {},
   "source": [
    "# **Getting Started**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478944b1-ad41-4c18-a1c1-351a215f6043",
   "metadata": {},
   "source": [
    "## **Preparation BEFORE the Loop:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7790bca1-f3dd-4210-b2a5-53d466fa811e",
   "metadata": {},
   "source": [
    "**Install, Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a93d3b88-d0d4-4752-9bbd-ba1aee5cdaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tmdbsimple in c:\\users\\asus tuf\\anaconda3\\envs\\dojo-env\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\asus tuf\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from tmdbsimple) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus tuf\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus tuf\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus tuf\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus tuf\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tmdbsimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de67d4d3-6956-4387-8fbb-94d44bd6b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os, time, json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd580a1f-cadf-46a3-b8e5-97cbdd2cfe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db250a02-15ac-4f6c-8dd8-f98553117719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tmdbsimple as tmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a11c5d-5f45-42f4-96fd-e5fec731ae13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['api-key'])\n"
     ]
    }
   ],
   "source": [
    "# Load TMDB API Key and add to tmdbsimple\n",
    "with open(r'C:\\Users\\ASUS TUF\\Documents\\GitHub\\ods-pt-data-enrichment-project\\.secret\\tmdb_api.json') as f:\n",
    "    login = json.load(f)\n",
    "print(login.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e501be3-37d8-4cf6-81b8-50c62ab0f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tmdbsimple and setting the API_KEY\n",
    "\n",
    "import tmdbsimple as tmdb\n",
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78364817-88ab-4fbc-b4eb-10de41224a2a",
   "metadata": {},
   "source": [
    "**Designate a folder**\n",
    "\n",
    "You will save API call data in the data folder you created for project Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76406df-1eae-46ef-b6b6-c7bc131b9040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'final_tmdb_data_2000.csv.gz',\n",
       " 'title-akas-us-only.csv',\n",
       " 'title-basics-us-only.csv',\n",
       " 'title-ratings-us-only.csv',\n",
       " 'title.basics.tsv.gz',\n",
       " 'title.ratings.tsv.gz',\n",
       " 'tmdb_api_results_2000.json']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the folder for saving files (if it doesn't exist)\n",
    "FOLDER = \"PracticeData/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "766fa5e8-9798-4cde-9b47-5cd7e51a8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you created the data folder for part 1, you will see your csv files listed here. If not, it will just be empty []."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84345afe-aa3f-44bb-942a-226c038d557d",
   "metadata": {},
   "source": [
    "**Define Your Functions**\n",
    "\n",
    "You should ultimately put any custom functions at the top of your notebook. You can first write them where you first use them in your project, but once you have the functions completed and tested, you should move their definitions to the top of your notebook after you import your packages.\n",
    "\n",
    "You will need your function to get the movie rating from the prior lesson, as well as the new function below: write_json. This is a modified version of a function from [https://www.geeksforgeeks.org/append-to-json-file-using-python/](https://www.geeksforgeeks.org/append-to-json-file-using-python/). Notice that the original source link is included in the function's docstring to give proper credit to the original authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25bc2891-b933-47e5-9395-9e2e0d84856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your functions\n",
    "def get_movie_with_rating(movie_id):\n",
    "    # Get the movie object for the current id\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    \n",
    "    # save the .info .releases dictionaries\n",
    "    movie_info = movie.info()\n",
    "    releases = movie.releases()\n",
    "    \n",
    "    # Loop through countries in releases\n",
    "    for c in releases['countries']:\n",
    "        # if the country abbreviation==US\n",
    "        if c['iso_3166_1' ] =='US':\n",
    "            ## save a \"certification\" key in the info dict with the certification\n",
    "            movie_info['certification'] = c['certification']\n",
    "    return movie_info\n",
    "\n",
    "\n",
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0134600-3a7c-4e42-94a1-ddbafb0d2100",
   "metadata": {},
   "source": [
    "**Confirm Your API Function works!**\n",
    "\n",
    "In order to ensure your function for extracting movie data from TMDB is working, test your function on these 2 movie ids: tt0848228 (\"The Avengers\") and tt0332280 (\"The Notebook\"). Make sure that your function runs without error and that it returns the correct movie's data for both test ids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b7383c-3a3c-4de5-9102-1256062b24f2",
   "metadata": {},
   "source": [
    "**Load in the Cleaned Title Basics data**\n",
    "\n",
    "You need to read in the filtered dataframe you created based on the specification of Project 2 Part 1.\n",
    "\n",
    "You will be filtering out the movies for each year inside the loop, so we will need this loaded and ready to be filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e6f35f3-e8fb-409f-b212-0ddb34131add",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34802</td>\n",
       "      <td>tt0035423</td>\n",
       "      <td>movie</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>Comedy,Fantasy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61114</td>\n",
       "      <td>tt0062336</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Tango of the Widower and Its Distorting Mi...</td>\n",
       "      <td>El tango del viudo y su espejo deformante</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67666</td>\n",
       "      <td>tt0069049</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86793</td>\n",
       "      <td>tt0088751</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>Comedy,Horror,Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93930</td>\n",
       "      <td>tt0096056</td>\n",
       "      <td>movie</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "      <td>0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86974</th>\n",
       "      <td>10016149</td>\n",
       "      <td>tt9914942</td>\n",
       "      <td>movie</td>\n",
       "      <td>Life Without Sara Amat</td>\n",
       "      <td>La vida sense la Sara Amat</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86975</th>\n",
       "      <td>10016544</td>\n",
       "      <td>tt9915872</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Last White Witch</td>\n",
       "      <td>My Girlfriend is a Wizard</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>Comedy,Drama,Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86976</th>\n",
       "      <td>10016684</td>\n",
       "      <td>tt9916170</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Rehearsal</td>\n",
       "      <td>O Ensaio</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86977</th>\n",
       "      <td>10016693</td>\n",
       "      <td>tt9916190</td>\n",
       "      <td>movie</td>\n",
       "      <td>Safeguard</td>\n",
       "      <td>Safeguard</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>Action,Adventure,Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86978</th>\n",
       "      <td>10016777</td>\n",
       "      <td>tt9916362</td>\n",
       "      <td>movie</td>\n",
       "      <td>Coven</td>\n",
       "      <td>Akelarre</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>Drama,History</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86979 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     tconst titleType  \\\n",
       "0           34802  tt0035423     movie   \n",
       "1           61114  tt0062336     movie   \n",
       "2           67666  tt0069049     movie   \n",
       "3           86793  tt0088751     movie   \n",
       "4           93930  tt0096056     movie   \n",
       "...           ...        ...       ...   \n",
       "86974    10016149  tt9914942     movie   \n",
       "86975    10016544  tt9915872     movie   \n",
       "86976    10016684  tt9916170     movie   \n",
       "86977    10016693  tt9916190     movie   \n",
       "86978    10016777  tt9916362     movie   \n",
       "\n",
       "                                            primaryTitle  \\\n",
       "0                                         Kate & Leopold   \n",
       "1      The Tango of the Widower and Its Distorting Mi...   \n",
       "2                             The Other Side of the Wind   \n",
       "3                                      The Naked Monster   \n",
       "4                                   Crime and Punishment   \n",
       "...                                                  ...   \n",
       "86974                             Life Without Sara Amat   \n",
       "86975                               The Last White Witch   \n",
       "86976                                      The Rehearsal   \n",
       "86977                                          Safeguard   \n",
       "86978                                              Coven   \n",
       "\n",
       "                                   originalTitle  isAdult  startYear  endYear  \\\n",
       "0                                 Kate & Leopold        0     2001.0      NaN   \n",
       "1      El tango del viudo y su espejo deformante        0     2020.0      NaN   \n",
       "2                     The Other Side of the Wind        0     2018.0      NaN   \n",
       "3                              The Naked Monster        0     2005.0      NaN   \n",
       "4                           Crime and Punishment        0     2002.0      NaN   \n",
       "...                                          ...      ...        ...      ...   \n",
       "86974                 La vida sense la Sara Amat        0     2019.0      NaN   \n",
       "86975                  My Girlfriend is a Wizard        0     2019.0      NaN   \n",
       "86976                                   O Ensaio        0     2019.0      NaN   \n",
       "86977                                  Safeguard        0     2020.0      NaN   \n",
       "86978                                   Akelarre        0     2020.0      NaN   \n",
       "\n",
       "       runtimeMinutes                     genres  \n",
       "0                 118     Comedy,Fantasy,Romance  \n",
       "1                  70                      Drama  \n",
       "2                 122                      Drama  \n",
       "3                 100       Comedy,Horror,Sci-Fi  \n",
       "4                 126                      Drama  \n",
       "...               ...                        ...  \n",
       "86974              74                      Drama  \n",
       "86975              97       Comedy,Drama,Fantasy  \n",
       "86976              51                      Drama  \n",
       "86977              95  Action,Adventure,Thriller  \n",
       "86978              92              Drama,History  \n",
       "\n",
       "[86979 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned Title Basics (from Part 1)\n",
    "basics = pd.read_csv('Data/title-basics-us-only.csv')\n",
    "basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8db649-e8ce-4a95-9f35-c3225d0acb7f",
   "metadata": {},
   "source": [
    "**Define a variable with the year to Extract from the API**\n",
    "\n",
    "We have data from 2000 - 2020 available. For this assignment, you will just retrieve data for the year 2010. We will save the year as a variable so that we can easily reuse it within our code and also our filenames.\n",
    "\n",
    "**Define an errors list**\n",
    "\n",
    "We will want to be able to save the ids and error messages for any movie that causes an error. To do so, we will want to create an empty errors list before our loops that we can append to later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e29713f-841d-489d-a6a7-c1b5eb549888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the year to filter for\n",
    "YEAR = 2010\n",
    "\n",
    "# Create an empty list for saving errors\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f3cb7-5f1b-4459-880c-b3ca9d598e53",
   "metadata": {},
   "source": [
    "**Prepare the DataFrame and JSON File**\n",
    "\n",
    "* Select a JSON_FILE filename to save the results in progress.\n",
    "\n",
    "First, define the file path, including the year. For the project, you are going to have multiple files, one for each year of movies. The code below will identify the folder in the FOLDER we just defined above and will name the file based on the current year.\n",
    "\n",
    "Determine if the JSON file exists:\n",
    "\n",
    "Check if that file already exists or not. If you are going through this lesson for the first time, it is very unlikely that the file exists! But, if you are at a different point in the project, and it already exists, we don't need to do anything, but just make sure it is a file you want to add to!\n",
    "\n",
    "If it does not exist:\n",
    "\n",
    "* Print f\"Creating {filename} for API results for {YEAR}.\"\n",
    "* Create an empty JSON file using with open that just contains a dictionary with the key \"imdb_id\" and the value 0.\n",
    "    * We will be appending to this empty dictionary throughout our calls.\n",
    "* If it already exists:\n",
    "    * Print \"The file {JSON_FILE} already exists.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab0459ff-2109-47f2-92e1-28ef13170a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Data/tmdb_api_results_2010.json for API results for year=2010.\n"
     ]
    }
   ],
   "source": [
    "# Define the JSON file to store results for the year\n",
    "JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "\n",
    "\n",
    "# Check if the JSON file exists\n",
    "file_exists = os.path.isfile(JSON_FILE)\n",
    "\n",
    "# If it does not exist: create it\n",
    "if file_exists == False:\n",
    "    print(f\"Creating {JSON_FILE} for API results for year={YEAR}.\")\n",
    "    \n",
    "    # save an empty dict with just \"imdb_id\" to the new json file.\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([{'imdb_id':0}],f)\n",
    "\n",
    "# If it exists, print a message\n",
    "else:\n",
    "    print(f'The file {JSON_FILE} already exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af45e7b-29b0-49dc-99d9-92870960e5a9",
   "metadata": {},
   "source": [
    "* Filter for the selected year and save the movie ids**\n",
    "\n",
    "For the project, you will be breaking up the title_basics data by year. For this practice assignment, we will only be extracted data for the year 2010.\n",
    "\n",
    "We will create a new DataFrame by filtering title_basics for the selected YEAR. We will then save the list of movie_ids as a separate variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f21d2b-dc3c-4317-ae35-ab349f5fe12a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1138    tt0230212\n",
       "3806    tt0312305\n",
       "4258    tt0326965\n",
       "4436    tt0331312\n",
       "6670    tt0393049\n",
       "Name: tconst, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering for movies from selected startYear\n",
    "df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "# saving movie ids to list\n",
    "movie_ids = df['tconst']\n",
    "movie_ids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6765846-1b01-4dd3-a480-fad6fc4cd452",
   "metadata": {},
   "source": [
    "**Check previous results and create the final list of movie_ids_to_get**\n",
    "\n",
    "You may remember from our lesson on efficient API calls that we are going to build in some safeguards when looping through multiple calls.\n",
    "\n",
    "    * Load in any existing API results with pd.read_json\n",
    "    * Check to see if any of the movie_ids to get are already in the JSON file.\n",
    "    * Filter out only movies that are missing from the JSON file to use in the loop\n",
    "\n",
    "The code loads any existing information from the JSON file into a dataframe called the \"previous_df.\" This will start empty, but as you iterate through the loop, it will continue to have more and more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c575de20-2ea2-40df-be4d-a9501ba432e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdb_id\n",
       "0        0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load existing data from json into a dataframe called \"previous_df\"\n",
    "previous_df = pd.read_json(JSON_FILE)\n",
    "previous_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3feae39-a31e-419a-98c8-a8ff2f3ec478",
   "metadata": {},
   "source": [
    "**Check for and filter out movie IDs that already exist**\n",
    "\n",
    "The next line of code will prevent you from wasting API calls on data you already have. Note that it is defining the ids you are calling in such a way that it excludes any ids that are already present in the previous_df. You may recall that this will also allow you to \"pick up where you left off\" if your API call gets interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfe536b8-6f62-4a82-aab0-242a975ba521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter out any ids that are already in the JSON_FILE\n",
    "movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272f0e1-3523-4bbc-a12a-eec6f6f066b7",
   "metadata": {},
   "source": [
    "Now we have defined the \"movie_ids_to_get\". It includes the ids from our dataframe in the year we are seeking, and it excludes any that we have already made calls for. We will use this list for our loop of API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c70482-e1a1-42e4-92f6-887dc4346eae",
   "metadata": {},
   "source": [
    "**Start Loop Through Movie IDs**\n",
    "\n",
    "Now that we have the filtered list of movie_ids_to_get for the current year, we will now create an inner loop to iterate through the movie_ids_to_get, and for each ID, we will: retrieve the movie info from the TMDB API, append the movie_info dictionary to our JSON_FILE, wait 20 ms to avoid overwhelming the API.\n",
    "\n",
    "**Set up Progress Bar*\n",
    "\n",
    "We want to keep track of our progress and ensure our calls are working. The progress bar works within the for statement of the for loop. Note that this will iterate through each year that is defined in the YEARS_TO_GET variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d70490a8-3dac-4bdd-8925-3c0e59902418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3023dca5f10746718c15ed8d74fb2f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2010:   0%|          | 0/3862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through movie_ids_to_get with a tqdm progress bar\n",
    "for movie_id in tqdm_notebook(movie_ids_to_get, f\"Movies from {YEAR}\"):\n",
    "\n",
    "    # Attempt to retrieve then data for the movie id\n",
    "    try:\n",
    "        temp = get_movie_with_rating(movie_id)  #This uses your pre-ma    de function\n",
    "        # Append/extend results to existing file using a pre-made function\n",
    "        write_json(temp,JSON_FILE)\n",
    "        # Short 20 ms sleep to prevent overwhelming server\n",
    "        time.sleep(0.02)\n",
    "\n",
    "    # If it fails,  make a dict with just the id and None for certification.\n",
    "    except Exception as e:\n",
    "        errors.append([movie_id, e])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d7618-ed14-4717-a586-7b32c844fdc2",
   "metadata": {},
   "source": [
    "***Earlier, ran year 2000***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f305be3-07e2-4798-a16c-1dfc17cf5edb",
   "metadata": {},
   "source": [
    "Ultimately we will be creating a loop, but let's explore each piece of the code:\n",
    "\n",
    "**Iterate through the list of Movie IDs and make the calls**\n",
    "\n",
    "The code below relies on the function you wrote in the previous lesson that made API calls and added the certification to the .info results. Here this function is named \"get_movie_with_rating\". Make sure you have the function from the earlier lesson in the code file before you plan to call on it! This loop also uses the function above (write_json) to extend/append the results to the .json file. **Make sure both functions are defined in your code file before you try to call them!**\n",
    "\n",
    "Since some movies exist in IMDB's title basics dataset (our DataFrame) that do not exist within the database for TMDB's API, we will get an error whenever we attempt to retrieve a movie id that TMDB does not have in its database.\n",
    "\n",
    "To get around this, we will use a try and except statement around our API extraction code. We will TRY to retrieve and save the data for the current movie_id, but if we get an error, we will save the movie_id and error message in our errors list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc9c0c9-60d1-4d6c-a37a-5514770d4998",
   "metadata": {},
   "source": [
    "**After the Loop**\n",
    "\n",
    "*Print a message reporting back the number of movie ids that caused an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90f4eba1-2aeb-4cb9-884b-878ed6fa2baa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Total errors: 1114\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Total errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5664cf93-9f01-48b5-9795-b3a42baab4ed",
   "metadata": {},
   "source": [
    "Once the inner loop through the movie_ids_to_get has finished, we will have all of our results for that year in our JSON_FILE. We now want to save them in a smaller file format.\n",
    "\n",
    "**Save the year's results as csv.gz file**\n",
    "\n",
    "Once all of the API calls for the current year are made, you should open your .json file with pd.read_json and convert each json file to a compressed csv (\".csv.gz\") to save space. This is done after the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b1ea0df-d011-4ab4-b750-914392cc0484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the final results to a csv.gz file\n",
    "final_year_df = pd.read_json(JSON_FILE)\n",
    "\n",
    "csv_fname = f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\"\n",
    "final_year_df.to_csv(csv_fname, compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391175e9-21ab-4e9d-87e0-b92a3b533786",
   "metadata": {},
   "source": [
    "# Troubleshooting:\n",
    "\n",
    "If you get an error message when trying to run pd.read_json, try replacing pd.read_json with the \"read_and_fix_json\" helper function in this repository: https://github.com/coding-dojo-data-science/data-enrichment-helper-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8279a38-c46d-48d1-979b-8581828c81b4",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746c53f-2958-4ea5-b5e1-2b780a524fbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "This lesson exemplifies the importance of planning your complex coding tasks so that you are clear on what you are trying to do in plain language before translating to code. While this lesson shows examples of the some of the code that you may want to use in the next phase of the project, remember it is still up to you to read and understand each step so that you can put together the final product!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04153625e3044d5aa32418bb573442e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1901a0f6b9e04124963226fd5830efad",
       "style": "IPY_MODEL_e62af4bad3884d1fadba6a4e8e3d83ba",
       "value": " 3862/3862 [1:08:59&lt;00:00,  1.28it/s]"
      }
     },
     "1901a0f6b9e04124963226fd5830efad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2956a0ccd1f84f40aecd3530646eec46": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3023dca5f10746718c15ed8d74fb2f83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fa2f05dafbd846ee976222e59b0c4249",
        "IPY_MODEL_a8f1d69b63c54f66ad5fd752672ab21e",
        "IPY_MODEL_04153625e3044d5aa32418bb573442e3"
       ],
       "layout": "IPY_MODEL_d87f0fd7fdf04c1a8a64ae2de8529f0c"
      }
     },
     "6480d97538da4695b996526baaa461bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a8f1d69b63c54f66ad5fd752672ab21e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_2956a0ccd1f84f40aecd3530646eec46",
       "max": 3862,
       "style": "IPY_MODEL_e1a4175f1bbf4a1b96f4292916b9f0fb",
       "value": 3862
      }
     },
     "aff6e54413724bb8b067801cec598030": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d87f0fd7fdf04c1a8a64ae2de8529f0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1a4175f1bbf4a1b96f4292916b9f0fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e62af4bad3884d1fadba6a4e8e3d83ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fa2f05dafbd846ee976222e59b0c4249": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6480d97538da4695b996526baaa461bb",
       "style": "IPY_MODEL_aff6e54413724bb8b067801cec598030",
       "value": "Movies from 2010: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
